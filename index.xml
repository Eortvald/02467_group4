<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Amazon fine foods reviews on Social Science Exam project</title><link>https://nullerh.github.io/02467_group4/</link><description>Recent content in Amazon fine foods reviews on Social Science Exam project</description><generator>Hugo -- gohugo.io</generator><atom:link href="https://nullerh.github.io/02467_group4/index.xml" rel="self" type="application/rss+xml"/><item><title>Data description</title><link>https://nullerh.github.io/02467_group4/data-description/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://nullerh.github.io/02467_group4/data-description/</guid><description>The data of this analysis are reviews of Amazon fine food products as well as some metadata for the products in the reviews. For the reviews themselves we have some
The 1139892 reviews of 39320 products are loaded into a pandas dataframe. Each row in the dataframe corresponds to a review and each column is a variable for the review. Below, we&amp;rsquo;ve included a snippet of the review dataframe.
The header in each column explains the variables of the review in each row.</description></item><item><title>Network analysis</title><link>https://nullerh.github.io/02467_group4/network-analysis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://nullerh.github.io/02467_group4/network-analysis/</guid><description>Constructing the Network of fine-food products In order to analyze the relation between Amazon fine-food products based on the users action, we construct a network accordingly. When buidling the network of products we connect products that have been bought and viewed together at least 15 times by the same user. This means that, if two products (product1/product2) in the network are linked, after buying product1 the user has bought/viewed at least 15 other products that the user has also bought/viewed after buying product2.</description></item><item><title>Text analysis</title><link>https://nullerh.github.io/02467_group4/text-analysis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://nullerh.github.io/02467_group4/text-analysis/</guid><description>First and foremost clean and tokenize the review texts. Everything is lowercased, stemmed, stopwords and hyperlinks are removed, as well as backslash commands that may appear.
Since the result of the text analysis is heavily dependent on the preprocessing we actually performed the whole analysis and then went back and changed the preprocessing, realizing that we should use stemming, remove some irrelevant words, which made the text analysis a recursive proces.</description></item></channel></rss>