<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Data description | Social Science Exam project</title><script src=https://cdn.tailwindcss.com></script><script src=https://unpkg.com/feather-icons></script><script src=https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js></script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><style type=text/tailwindcss>
    @layer base {
        body {
          @apply bg-gray-100;
          @apply font-sans;
          @apply leading-normal;
          @apply tracking-normal;
        }
        p {
          @apply py-6;
        }
        a {
          @apply text-green-500;
          @apply no-underline;
          @apply hover:underline;
        }
        h1 {
          @apply py-2;
          @apply font-sans;
          @apply text-2xl;
        }
        h2 {
          @apply py-2;
          @apply font-sans;
          @apply text-xl;
        }
        h3 {
          @apply py-2;
          @apply font-sans;
          @apply text-lg;
        }
        ol {
          @apply px-8;
          @apply list-decimal;
        }
        ul {
          @apply px-8;
          @apply list-disc;
        }
        blockquote {
          @apply border-l-4; 
          @apply border-green-500;
          @apply italic;
          @apply my-8;
          @apply pl-8;
          @apply md:pl-12;
        }
        pre {
          @apply bg-gray-900;
          @apply rounded;
          @apply text-white; 
          @apply font-mono;
          @apply text-base;
          @apply my-4;
          @apply p-2;
          @apply md:p-4;
        }
        table {
          @apply shadow-md;
          @apply rounded-lg;
          @apply m-auto;
          @apply my-8;
        }
        thead {
          @apply bg-gray-50;
        }
        th {
          @apply py-3;
          @apply px-6;
          @apply text-xs;
          @apply font-medium;
          @apply tracking-wider;
          @apply text-left;
          @apply text-gray-700;
          @apply uppercase;
        }
        tr {
          @apply bg-white;
          @apply border-b;
        }
        td {
          @apply py-4;
          @apply px-6;
          @apply text-sm;
          @apply font-medium;
          @apply text-gray-900;
          @apply whitespace-nowrap;
        }
        img {
          @apply m-auto;
          @apply object-cover;
        }
        .footer-icon {
          width: 64px; 
          height: 64px;
          @apply mx-4;
        }
      }
    </style></head><body><nav id=header class="fixed w-full z-10 top-0"><div id=progress class="h-1 z-20 top-0" style="background:linear-gradient(to right,#4dc0b5 var(--scroll),transparent 0)"></div><div class="w-full md:max-w-4xl mx-auto flex flex-wrap items-center justify-between mt-0 py-3"><div class=pl-4><a class="text-gray-900 text-base no-underline hover:no-underline font-extrabold text-xl" href=https://nullerh.github.io/02467_group4/>Social Science Exam project</a></div><div class="block lg:hidden pr-4"><button id=nav-toggle class="flex items-center px-3 py-2 border rounded text-gray-500 border-gray-600 hover:text-gray-900 hover:border-green-500 appearance-none focus:outline-none"><svg class="fill-current h-3 w-3" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><title>Menu</title><path d="M0 3h20v2H0V3zm0 6h20v2H0V9zm0 6h20v2H0v-2z"/></svg></button></div><div class="w-full flex-grow lg:flex lg:items-center lg:w-auto hidden lg:block mt-2 lg:mt-0 bg-gray-100 md:bg-transparent z-20" id=nav-content><ul class="list-reset lg:flex justify-end flex-1 items-center list-none px-0"><li><a class="inline-block py-2 px-4 text-gray-900 no-underline" href=../data-description>Data</a></li><li><a class="inline-block py-2 px-4 text-gray-900 no-underline" href=../network-analysis>Network</a></li><li><a class="inline-block py-2 px-4 text-gray-900 no-underline" href=../text-analysis>Text</a></li></ul></div></div></nav><div class="container w-full md:max-w-3xl mx-auto pt-20"><div class="w-full px-4 md:px-6 text-xl text-gray-800 leading-normal" style=font-family:Georgia,serif><div class=font-sans><h1 class="font-bold font-sans break-normal text-gray-900 pt-6 pb-2 text-3xl md:text-4xl">Data description</h1></div><p>The data of this analysis are reviews of Amazon fine food products as well as some
metadata for the products in the reviews. For the reviews themselves we have some</p><p>The 1139892 reviews of 39320 products are loaded into a pandas dataframe. Each row in the dataframe
corresponds to a review and each column is a variable for the review. Below, we&rsquo;ve
included a snippet of the review dataframe.</p><img src=../images/data_example.PNG title="Snippet of 2 reviews"><p>The header in each column explains the variables of the review in each row. Firstly,
we have an <em>overall</em> review score corresponding to how many &lsquo;stars&rsquo; the reviewer gave
the product on a scale of 1-5. The <em>verified</em> column is true if the user that reviewed
the product actually has a purchase of the product which is verified by Amazon.
Next, there&rsquo;s a
<em>reviewTime</em> in month/day/year format, a <em>reviewerID</em> and <em>asin</em> is simply the product
code for the reviewed item. The <em>reviewerName</em> is simply the profile name of the user
that reviewed the product. The <em>reviewText</em> is the comment and the <em>summary</em> is the
&lsquo;headline&rsquo; of the comment and the right-most <em>TEXT</em> variable is a combination of
these two. <em>unixReviewTime</em> is the review time in unix (so the number of seconds
since 00:00:00 UTC on January 1st 1970). The <em>vote</em> is a variable that contains
other users' opinion on this specific review. Other users can vote on if a review
is &lsquo;helpful&rsquo; which will show here. <em>style</em> contains information regarding
specifications of the product (weight/volume/6-pack/packaging etc.)
<em>image</em> refer to images they may be attached to the review.
We will mainly keep track of</p><p>Since we suspect that some of the reviews are made by bots, we exclude these reviews based
on some common criteria:</p><ul><li>The same userID submitted multiple reviews within seconds of one another.</li><li>The same userID left multiple reviews of the same product.</li><li>Users review different products with the same review/title for the products</li><li>Multiple users making identical reviews for a product.</li></ul><p>We choose to be tough on bot-like reviews since the dataset is so large.
For instance this user posted multiple very similar reviews on the same product.</p><img src=../images/repeated_review.PNG><p>As mentioned, we also have metadata on the products that are being reviewed. The
metadata contains information about specific products. We load it in a pandas
dataframe and similarly to the review data, there are 39320 rows corresponding to
each unique product. The columns are variables regarding each of the products. We
have the following variables:
<em>category</em> contains a category and all the subcategories the product belongs to.
Almost all the products are in the same category &ldquo;Grocery and Gourmet food&rdquo;. But for
instance a teabag will have the subcategory &ldquo;Beverages&rdquo; and the sub-subcategory
&ldquo;Coffee, tea and XXXXXXXXXX&rdquo;. <em>title</em> and <em>description</em> contains the title
and description of the product. We also have the same <em>asin</em> product code.
<em>also_buy</em> contains the <em>asin</em> product codes for
products that users have also bought alongside this product, and likewise with
<em>also_view</em> that contains the <em>asin</em> code for items that we&rsquo;re also viewed. The
metadata also contains <em>brand</em>, <em>price</em>, <em>similar_item</em>s as well as hyperlinks to
the images in the product site named <em>imageURL</em> and <em>imageURLHighRes</em>. Some products
have <em>details</em> e.g. dimensions of the product. Likewise, some products have <em>feature</em>
containing e.g. certifications of the product.
There&rsquo;s a <em>rank</em> of the products listed after how well they sell, a <em>date</em> of when
they were listed and <em>main_cat</em> which is mostly grocery since this is the category
we&rsquo;re the most interested in. Lastly, we have a <em>tokens</em> connected with each unique
product.</p><h1 id=cleaning-and-tokenization>Cleaning and tokenization</h1><p>As mentioned above, we removed all reviews that we&rsquo;re deemed to be written by a bot from the simple
criteria listed above. Furthermore, we make documents for each product containing a tokenized version
of the review text. This is simply done using the <em>asin</em> product code to get
all reviews of a product. You can see in detail what has been done in the explainer-notebook.html.</p><h1 id=the-ten-characteristics-of-big-data>The ten characteristics of big data</h1><ol><li>Big<ul><li>The dataset is very large. It would not be feasible to collect the same amount of data by e.g. surveys.</li></ul></li><li>Always-on<ul><li>Since reviews are constantly being made we simply take data from a specified period, since the
analysis is not time sensitive.</li></ul></li><li>Nonreactive<ul><li>Since the point of a review is for other people to read it, we must assume that the data is not nonreactive.</li></ul></li><li>Incomplete<ul><li>Obviously it would be nice to have more information but in this case the analysis was designed to
fit the data.</li></ul></li><li>Inaccessible<ul><li>This data is something that Amazon has released. We wouldn&rsquo;t be able to get this data ourselves since
Amazon enforces a re-captcha when applying modules like BeautifulSoup to scrape reviews.</li></ul></li><li>Nonrepresentative<ul><li>Our data revolves around analysing reviewers. So the users is the population, which they are completely
representative of. If we were to generalize any results we would have to keep in mind that the users who
review product might not necessarily be representative of the general population. There are some confounders
that can affect representation that will be discussed in <em>Algorithmically confounded</em></li></ul></li><li>Drifting<ul><li>We cannot exclude the possibility of either population-, behavioral-, or system drift. But since the
analysis is not time sensitive it shouldn&rsquo;t pose too much of an issue. We can obviously imagine that the
users change over time, or that the pandemic affected the review score of products or that updates from
of Amazon.com could change some tendencies of the reviews.</li></ul></li><li>Algorithmically confounded<ul><li>This is quite an important point to make. Amazon has incentive to make users review as many products
as possible to increase the user experience on their website, especially positive reviews in order to
sell more products. There have been stories of sellers offering users double refunds to take
down negative reviews as these are absolutely detrimental for their products to compete, and there are
also many stories of users having their reviews deleted which creates confounders in the data.</li></ul></li><li>Dirty<ul><li>Amazon tries to regulate bot reviews, at least seemingly. But it is impossible to know what&rsquo;s going on
behind the scenes in Amazon offices. We must assume that not all reviews are human-made which is why we
clean the data.</li></ul></li><li>Sensitive<ul><li>The data isn&rsquo;t sensitive as it is expected from the user that the reviews are being read.</li></ul></li></ol><hr class="border-b-2 border-gray-400 mt-8 mx-4"><div class="font-sans flex justify-between content-center px-4 pb-12"><div class=text-left><p><a href=https://nullerh.github.io/02467_group4/ class="break-normal text-base md:text-sm text-green-500 font-bold no-underline hover:underline">&lt;
Previous Page</a></p></div><div class=text-right><p><a href=../network-analysis class="break-normal text-base md:text-sm text-green-500 font-bold no-underline hover:underline">Next
Page ></a></p></div></div></div></div><footer class="bg-white border-t border-gray-400 shadow"><div class="container max-w-4xl mx-auto flex py-8"><div class="w-full mx-auto flex flex-col"><div class="flex w-full"><div class="px-8 mx-auto"><ul class="pt-3 list-none px-0 flex"><li><a class="text-gray-600 no-underline py-2" href=../explainer-notebook.html><i data-feather=file-text class=footer-icon></i></a></li><li><a class="text-gray-600 no-underline py-2" href=https://github.com/nullerh/02467_group4><i data-feather=github class=footer-icon></i></a></li><li><a class="text-gray-600 no-underline py-2" href=https://drive.google.com><i data-feather=hard-drive class=footer-icon></i></a></li></ul></div></div><div class="w-full mx-auto text-center"><ul class="list-reset items-center text-md py-6 list-none flex"><li class=mx-auto><p class="inline-block text-gray-600 mx-4 font-semibold capitalized">Emil Ortvald</p></li><li class=mx-auto><p class="inline-block text-gray-600 mx-4 font-semibold capitalized">Joachim Christensen</p></li><li class=mx-auto><p class="inline-block text-gray-600 mx-4 font-semibold capitalized">Peter Hulgaard</p></li></ul></div></div></div></footer><script>var h=document.documentElement,b=document.body,st='scrollTop',sh='scrollHeight',progress=document.querySelector('#progress'),scrollpos=window.scrollY,header=document.getElementById("header"),navcontent=document.getElementById("nav-content"),scroll;document.addEventListener('scroll',function(){scroll=(h[st]||b[st])/((h[sh]||b[sh])-h.clientHeight)*100,progress.style.setProperty('--scroll',scroll+'%'),scrollpos=window.scrollY,scrollpos>10?(header.classList.add("bg-white"),header.classList.add("shadow"),navcontent.classList.remove("bg-gray-100"),navcontent.classList.add("bg-white")):(header.classList.remove("bg-white"),header.classList.remove("shadow"),navcontent.classList.remove("bg-white"),navcontent.classList.add("bg-gray-100"))}),document.getElementById('nav-toggle').onclick=function(){document.getElementById("nav-content").classList.toggle("hidden")},feather.replace()</script></body></html>