<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Text analysis | Amazon Fine Foods Project</title><script src=https://cdn.tailwindcss.com></script><script src=https://unpkg.com/feather-icons></script><script src=https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js></script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><style type=text/tailwindcss>
    @layer base {
        body {
          @apply bg-gray-100;
          @apply font-sans;
          @apply leading-normal;
          @apply tracking-normal;
        }
        p {
          @apply py-6;
        }
        a {
          @apply text-green-500;
          @apply no-underline;
          @apply hover:underline;
        }
        h1 {
          @apply py-2;
          @apply font-sans;
          @apply text-2xl;
        }
        h2 {
          @apply py-2;
          @apply font-sans;
          @apply text-xl;
        }
        h3 {
          @apply py-2;
          @apply font-sans;
          @apply text-lg;
        }
        ol {
          @apply px-8;
          @apply list-decimal;
        }
        ul {
          @apply px-8;
          @apply list-disc;
        }
        blockquote {
          @apply border-l-4; 
          @apply border-green-500;
          @apply italic;
          @apply my-8;
          @apply pl-8;
          @apply md:pl-12;
        }
        pre {
          @apply bg-gray-900;
          @apply rounded;
          @apply text-white; 
          @apply font-mono;
          @apply text-base;
          @apply my-4;
          @apply p-2;
          @apply md:p-4;
        }
        table {
          @apply shadow-md;
          @apply rounded-lg;
          @apply m-auto;
          @apply my-8;
        }
        thead {
          @apply bg-gray-50;
        }
        th {
          @apply py-3;
          @apply px-6;
          @apply text-xs;
          @apply font-medium;
          @apply tracking-wider;
          @apply text-left;
          @apply text-gray-700;
          @apply uppercase;
        }
        tr {
          @apply bg-white;
          @apply border-b;
        }
        td {
          @apply py-4;
          @apply px-6;
          @apply text-sm;
          @apply font-medium;
          @apply text-gray-900;
          @apply whitespace-nowrap;
        }
        img {
          @apply m-auto;
          @apply object-cover;
        }
        .footer-icon {
          width: 64px; 
          height: 64px;
          @apply mx-4;
        }
      }
    </style></head><body><nav id=header class="fixed w-full z-10 top-0"><div id=progress class="h-1 z-20 top-0" style="background:linear-gradient(to right,#4dc0b5 var(--scroll),transparent 0)"></div><div class="w-full md:max-w-4xl mx-auto flex flex-wrap items-center justify-between mt-0 py-3"><div class=pl-4><a class="text-gray-900 text-base no-underline hover:no-underline font-extrabold text-xl" href=https://eortvald.github.io/02467_group4/>Amazon Fine Foods Project</a></div><div class="block lg:hidden pr-4"><button id=nav-toggle class="flex items-center px-3 py-2 border rounded text-gray-500 border-gray-600 hover:text-gray-900 hover:border-green-500 appearance-none focus:outline-none"><svg class="fill-current h-3 w-3" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><title>Menu</title><path d="M0 3h20v2H0V3zm0 6h20v2H0V9zm0 6h20v2H0v-2z"/></svg></button></div><div class="w-full flex-grow lg:flex lg:items-center lg:w-auto hidden lg:block mt-2 lg:mt-0 bg-gray-100 md:bg-transparent z-20" id=nav-content><ul class="list-reset lg:flex justify-end flex-1 items-center list-none px-0"><li><a class="inline-block py-2 px-4 text-gray-900 no-underline" href=../data-description>Data</a></li><li><a class="inline-block py-2 px-4 text-gray-900 no-underline" href=../text-analysis>Text</a></li><li><a class="inline-block py-2 px-4 text-gray-900 no-underline" href=../network-analysis>Network</a></li><li><a class="inline-block py-2 px-4 text-gray-900 no-underline" href=../summary>Summary</a></li></ul></div></div></nav><div class="container w-full md:max-w-3xl mx-auto pt-20"><div class="w-full px-4 md:px-6 text-xl text-gray-800 leading-normal" style=font-family:Georgia,serif><div class=font-sans><h1 class="font-bold font-sans break-normal text-gray-900 pt-6 pb-2 text-3xl md:text-4xl">Text analysis</h1></div><p>For the text analysis we want to investigate sentiment scores in order to evalute how they compare to the amazon score. This is interesting since it will tells us how good the Hendometer sentiment weights generlize across different text domians. It will also tell os someting about how language is sorrounding review on amazon food reviews - do people use strong positive/negative language for there reviews?</p><p>In order to cunduct a proper text analysis we first need to clean up the text data. This consisted of removing numbers, and symbols from the text corpus, togehter with using regular expressions to remove patterns of text consituting HTML url embeddings, that some users sometimes would leave in there reviews to reference othe rproducts, we also removed unicode for newline, whitespace, special symbols and tabs. All the text was also lowered.</p><p>Further more in order to prepare the data for sentiment analysis and TF-DIF + Wordclouds, we remove stopwords, from the corpus. Our prior experince with the defualt stopwords in NLTK, was that is was is not, so we extended the stopwords from multipe sources among others - some commenly used in SQL quering.<br>For the tokenization we use NLTK tokenizer since this is an effective solution. Regarding stemming, we didnt find it fit for our use, among reasons was that the words in the Hendometer is not stemmed.</p><p>For constructing documents to use both for sentiment analysis and later for TF-IDF analysis, we combine all reviews tokens belogning to a product as one document, so we ended up with a list of tokens for each unique product. We also calculate the average score for each product from the all the reveiws, this we call just <code>score</code>.</p><p>In order to get the sentiment score of the reviews we use the Hedonometer sentiment score and
take the mean over the document for each product which yields a general <code>sentiment_score</code> of the product.</p><p>We then inspect the distribution of Amazon scores and Sentimet scores by vizualization</p><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td><img src=../images/amazon_score.png alt></td><td><img src=../images/amazon_score.png alt></td></tr></tbody></table><p>We see that there is a great imbalance in the Amazon reviews scores, a majority of products have very high scores, maybe even alarmingly high amount with the score 5.0.
Looking at the Sentiment score distribution we find that it is looking very normally distributed. We see the mean is located above the neutral score of 5. This is in accordancde with research done on other corpuses using the Hendometer wieghs - <a href=https://arxiv.org/abs/1406.3855>Human language reveals a universal positivity bias</a></p><p>We then look at the linear relationship between these two scorings.
<img src=../images/mean_amazon_sentiment.png></p><p>As can be seen on the figure above where we have the sentiment score on the y-axis and the
review score on the x-axis there&rsquo;s a correlation between sentiment and review score which isn&rsquo;t very
surprising as better reviews naturally contains more positive wording.<br>One interesting point to make is that the sentiment of the reviews are distributed around a
median score which is higher as the score grows, but even for all the 5-star reviews the
sentiment seems to be normally distributed and so there&rsquo;s quite a vast variety of sentiment
values for the reviews with the same score. This could imply that there are different opinions
on what constitutes a 5-star review or just that the reviewers have very different review styles.</p><p>We can see that there is a linear relationship, we calculate a correlation to be 0.4. Its not a very strong correlation but significant enough.
A explanation for why so many products has such a high score can be found in bias we might have induced ourselves - removing product with few reviews - where one can think that the product have fewer reviews was do to better product was brougth instead.</p><p>The general problem seems to be that the Hendometer weights does not scores the reviews as high as the actual given score from the reviewer itself. A explanation could be that the type of language that a person will use for a review is more structured, than a random &ldquo;statement&rdquo; from a user on a social network like twitter - here a user is likely rewarded (read: getting likes,shares and retweets) more for making more extreme wordings both negative or positive in order to grab attentions. Whereas for a reviews - a user it maybe more focused on getting facts and specification communicated cleary, and even though a review is a tale of experiences, they might word it in a more formal language in order to archive trust, respect and credibility</p><hr class="border-b-2 border-gray-400 mt-8 mx-4"><div class="font-sans flex justify-between content-center px-4 pb-12"><div class=text-left><p><a href=../data-description class="break-normal text-base md:text-sm text-green-500 font-bold no-underline hover:underline">&lt;
Previous Page</a></p></div><div class=text-right><p><a href=../network-analysis class="break-normal text-base md:text-sm text-green-500 font-bold no-underline hover:underline">Next
Page ></a></p></div></div></div></div><footer class="bg-white border-t border-gray-400 shadow"><div class="container max-w-4xl mx-auto flex py-8"><div class="w-full mx-auto flex flex-col"><div class="flex w-full"><div class="px-8 mx-auto"><ul class="pt-3 list-none px-0 flex"><li><a class="text-gray-600 no-underline py-2" href=../explainer-notebook.html><i data-feather=file-text class=footer-icon></i></a></li><li><a class="text-gray-600 no-underline py-2" href=https://github.com/Joachimchristensen/02467-comsocsci-examproject><i data-feather=github class=footer-icon></i></a></li><li><a class="text-gray-600 no-underline py-2" href=https://drive.google.com/drive/folders/1LdzDLUJ0fnkbmTHLJu8Zv6AfVEaCX0d4><i data-feather=hard-drive class=footer-icon></i></a></li></ul></div></div><div class="w-full mx-auto text-center"><ul class="list-reset items-center text-md py-6 list-none flex"><li class=mx-auto><p class="inline-block text-gray-600 mx-4 font-semibold capitalized">Emil Ortvald - s194276</p></li><li class=mx-auto><p class="inline-block text-gray-600 mx-4 font-semibold capitalized">Joachim Christensen - s173743</p></li><li class=mx-auto><p class="inline-block text-gray-600 mx-4 font-semibold capitalized">Peter Hulgaard - s194277</p></li></ul></div></div></div></footer><script>var h=document.documentElement,b=document.body,st='scrollTop',sh='scrollHeight',progress=document.querySelector('#progress'),scrollpos=window.scrollY,header=document.getElementById("header"),navcontent=document.getElementById("nav-content"),scroll;document.addEventListener('scroll',function(){scroll=(h[st]||b[st])/((h[sh]||b[sh])-h.clientHeight)*100,progress.style.setProperty('--scroll',scroll+'%'),scrollpos=window.scrollY,scrollpos>10?(header.classList.add("bg-white"),header.classList.add("shadow"),navcontent.classList.remove("bg-gray-100"),navcontent.classList.add("bg-white")):(header.classList.remove("bg-white"),header.classList.remove("shadow"),navcontent.classList.remove("bg-white"),navcontent.classList.add("bg-gray-100"))}),document.getElementById('nav-toggle').onclick=function(){document.getElementById("nav-content").classList.toggle("hidden")},feather.replace()</script></body></html>